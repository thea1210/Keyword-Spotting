@INPROCEEDINGS{10528680,
  author={Dhungana, Prakash and Salehi, Sayed Ahmad},
  booktitle={2024 25th International Symposium on Quality Electronic Design (ISQED)}, 
  title={RTKWS: Real-Time Keyword Spotting Based on Integer Arithmetic for Edge Deployment}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  keywords={Performance evaluation;Quantization (signal);Microcontrollers;Computational modeling;Neural networks;Memory management;Random access memory;Keyword Spotting;Edge Computing;Real-Time Operation;Short Time Fourier Transform;Compact Deep Neural Networks;Quantization;Quantized Inference},
  doi={10.1109/ISQED60706.2024.10528680}
}

@misc{SpeechRecog,
author = {Sid-Ahmed Selouani},
title = {Speech Processing and Soft Computing | SpringerLink},
howpublished = {\url{https://link-springer-com.dlsu.idm.oclc.org/book/10.1007/978-1-4419-9685-5}},
month = {},
year = {2011},
note = {(Accessed on 09/29/2024)}
}

@misc{Google,
author = {Google},
title = {Google Assistant, your own personal Google},
howpublished = {\url{https://assistant.google.com/}},
month = {},
year = {2024},
note = {(Accessed on 09/25/2024)}
}

@misc{Siri,
author = {},
title = {Siri - Apple},
howpublished = {\url{https://www.apple.com/siri/}},
month = {},
year = {2024},
note = {(Accessed on 09/25/2024)}
}

@article{KHEDDAR2024102422,
title = {Automatic speech recognition using advanced deep learning approaches: A survey},
journal = {Information Fusion},
volume = {109},
pages = {102422},
year = {2024},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2024.102422},
url = {https://www.sciencedirect.com/science/article/pii/S1566253524002008},
author = {Hamza Kheddar and Mustapha Hemis and Yassine Himeur},
keywords = {Automatic speech recognition, Deep transfer learning, Transformers, Federated learning, Reinforcement learning},
abstract = {Recent advancements in deep learning (DL) have posed a significant challenge for automatic speech recognition (ASR). ASR relies on extensive training datasets, including confidential ones, and demands substantial computational and storage resources. Enabling adaptive systems improves ASR performance in dynamic environments. DL techniques assume training and testing data originate from the same domain, which is not always true. Advanced DL techniques like deep transfer learning (DTL), federated learning (FL), and deep reinforcement learning (DRL) address these issues. DTL allows high-performance models using small yet related datasets, FL enables training on confidential data without dataset possession, and DRL optimizes decision-making in dynamic environments, reducing computation costs. This survey offers a comprehensive review of DTL, FL, and DRL-based ASR frameworks, aiming to provide insights into the latest developments and aid researchers and professionals in understanding the current challenges. Additionally, Transformers, which are advanced DL techniques heavily used in proposed ASR frameworks, are considered in this survey for their ability to capture extensive dependencies in the input ASR sequence. The paper starts by presenting the background of DTL, FL, DRL, and Transformers and then adopts a well-designed taxonomy to outline the state-of-the-art (SOTA) approaches. Subsequently, a critical analysis is conducted to identify the strengths and weaknesses of each framework. Additionally, a comparative study is presented to highlight the existing challenges, paving the way for future research opportunities.}
}

@misc{Amazon,
author = {Amazon},
title = {Alexa},
howpublished = {\url{https://alexa.amazon.com/}},
month = {},
year = {2024},
note = {(Accessed on 09/25/2024)}
}

@misc{TNML,
author = {GeeksforGeeks},
title = {What is TinyML? Tiny Machine Learning - GeeksforGeeks},
howpublished = {\url{https://www.geeksforgeeks.org/what-is-tinyml-tiny-machine-learning/}},
month = {},
year = {2024},
note = {(Accessed on 09/25/2024)}
}

@misc{EDGE,
author = {},
title = {Edge Impulse},
howpublished = {\url{https://edgeimpulse.com/faqs/}},
month = {},
year = {2024},
note = {(Accessed on 10/2/2024)}
}
